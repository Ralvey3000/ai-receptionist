from fastapi import FastAPI, Request, WebSocket
from openai import OpenAI
import os

# Create the FastAPI app
app = FastAPI()

# Create OpenAI client using API key from Railway environment variables
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ‚úÖ Test route to confirm Railway is working
@app.get("/")
def root():
    return {"message": "‚úÖ AI Receptionist server is running on Railway!"}

@app.get("/test")
def test_openai():
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Hello, AI receptionist!"}]
        )
        return {
            "status": "success",
            "sample_reply": response.choices[0].message.content
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}

# ‚úÖ Chat endpoint (fallback HTTP POST requests)
@app.post("/chat")
async def chat_endpoint(request: Request):
    try:
        data = await request.json()
        print("Incoming Retell HTTP request:", data)
        user_message = data.get("message") or data.get("input") or ""
        
        if not user_message:
            return {"reply": "Hi there! Thanks for calling. How can I help you today?"}
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a warm, professional receptionist. Sound natural, keep responses short, and make the caller feel comfortable."},
                {"role": "user", "content": user_message}
            ]
        )
        reply = response.choices[0].message.content
        return {"reply": reply}
    except Exception as e:
        print("Error in chat endpoint:", str(e))
        return {"reply": "Hi there! Thanks for calling. How can I help you today?"}

# ‚úÖ WebSocket endpoint for Retell Realtime Voice
@app.websocket("/chat/{call_id}")
async def websocket_endpoint(websocket: WebSocket, call_id: str):
    await websocket.accept()
    print(f"üìû WebSocket connection opened for call {call_id}")
    
    # Session ready
    await websocket.send_json({"type": "session.update", "status": "ready"})
    
    # Greeting using instructions + output_audio
    await websocket.send_json({
        "type": "response.create",
        "response_id": "greeting",
        "modalities": ["output_audio"],
        "instructions": "Hi! Thanks for calling. This is your receptionist speaking. How can I help today?"
    })
    print("üîÑ Sent greeting with instructions for audio")
    
    reply_counter = 0
    
    try:
        while True:
            caller_message = await websocket.receive_text()
            print(f"üé§ Caller said: {caller_message}")
            
            # Only respond to response_required
            if '"interaction_type":"response_required"' not in caller_message:
                print("‚ÑπÔ∏è Ignoring update_only event")
                continue
            
            # Generate GPT reply
            gpt_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a warm, professional receptionist. Keep responses short, natural, and human-like."},
                    {"role": "user", "content": caller_message}
                ]
            )
            reply_text = gpt_response.choices[0].message.content
            print(f"ü§ñ AI reply: {reply_text}")
            
            # Unique response_id for each reply
            reply_counter += 1
            reply_id = f"reply_{reply_counter}"
            
            # Send Retell output with instructions only
            await websocket.send_json({
                "type": "response.create",
                "response_id": reply_id,
                "modalities": ["output_audio"],
                "instructions": reply_text
            })
            print(f"üîÑ Sent instructions for {reply_id}")
    
    except Exception as e:
        print(f"‚ùå WebSocket closed for call {call_id}: {e}")

